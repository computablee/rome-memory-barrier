## This project will be deleted soon!

Due to GitHub's unfortunate new practice of using repositories to train Microsoft LLMs, I have made the difficult decision to migrate all of my projects to [Codeberg](https://codeberg.org/).

Because of this project's low visibility, I have decided that it is not important enough to keep on GitHub.
**Therefore, I have decided to delete this project at some point during the month of September.**
[This project's new home can be found here.](https://codeberg.org/computablee/rome-memory-barrier)

# The AMD Rome Memory Barrier
The term project for CPE 631 at the University of Alabama in Huntsville. This project explored the limitations of memory bandwidth on an AMD Rome system. This repository hold the capability to compile the SPEC CPU2017 benchmarking suite in addition to the collection of PMC events during runtime using AMDuProf. For futher details, view the report available under "The AMD Rome Memory Barrier.pdf."

## Directory Structure
### graphs
This directory contains the Excel files for all graphs used in the report.

### parser_scripts
This directory holds the scripts for parsing the results generated by AMDuProfPcm. The `events_parser.py` and `metrics_parser.py` parse through the original outputs from AMDuProfPcm. The `verify_parser.py` script verifies some of the calculations done by the first two scripts. The `graph_parser.py` script creates different CSVs to be used for easier access to data we wanted to graph. The `table_parser.py` script creates the two CSVs per SPEC CPU2017 suite for core metrics and cache breakdown. The `scale_parser.py` script condenses the results from the Scalability tests into Integer Rate and Floating Point Rate CSVs. A README.txt file in this directory explains how to execute the scripts.

### reportable
This directory contains the SPEC generated PDFs from the reportable runs.

### results
#### graph_data
This directory is the output from the `graph_parser.py` script and holds directories for each SPEC CPU2017 benchmark suite (`fp_rate`, `fp_speed`, `int_rate`, and `int_speed`) as well as scalability test results for Integer and Floating Point Rate suites. Each of the subdirectories contains a cache breakdown, memory bandwidth--CPI correlation, general core parameters, IPC, and pipeline utilization CSVs for all benchmarks in the suite.

#### scale_results
This directory contains execution time for each instance count of each rate benchmark (both Integer and Floating Point).

#### uprof_results
This directory contains the AMDuProfPcm results. Within each benchmark subdirectory is a `metrics.csv` which contains common metrics and `events.csv` which contains raw PCMs.

#### uprof_results_cumulative
This directory is the output from the `events_parser.py` and the `metrics_parser.py` scripts. The directory contains a subdirectory for each benchmark and contains the aggregate data across all cores utilized during the Monitoring Test.

### run_scripts
This directory contains bash scripts for compiling, running, and profiling the SPEC CPU2017 benchmarks. 

## Other Files
### `aocc-3.1.0-linux.cfg`
This file is the configuration file for compiling SPEC CPU2017 benchmarks for use with AMDuProfPcm.

### `aocc-reportable-3.1.0-linux.cfg`
This file is for compiling for the reportable runs. Note, that some compile flags are different due to AMDuProf requiring certain flags that are illegal for reportable runs.

### `icx-2021.3.0-linux.cfg`
This file compiles for reportable runs with the Intel OneAPI compiler.

### `spec-config.conf`
This is the configuration file for AMDuProfPcm.
